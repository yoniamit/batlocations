{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Copy of find basket.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoniamit/batlocations/blob/main/batlocation130421b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vizeIq2pgMA",
        "outputId": "95bd6b2f-2e50-42be-9095-c1e99a30b0b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgil14Kj1YnQ"
      },
      "source": [
        "#Imports\n",
        "import math\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from scipy.interpolate import interp1d\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pickle\n",
        "\n",
        "\n",
        "#Definations\n",
        "\n",
        "xlb = 320.0  # x left basket\n",
        "ylb = 410.0  # y left basket\n",
        "xrb = 420.0  # x right basket\n",
        "yrb = 60.0  # y right basket\n",
        "basketradius = 40.0  # distance from the center of the basket which count as \"IN\"\n",
        "accuracy_limit = 0.0  # Value for accuracy check \n",
        "\n",
        "nans_tresh  = 0.3\n",
        "per_unit = 60\n",
        "gmmcomp = 3\n",
        "tresh_sleep_distance = 10\n",
        "\n",
        "#data_read_path = \"/content/drive/MyDrive/Python files/20210311-161231IrTimes.txt\" #path_of data to read\n",
        "#data_read_path = \"/content/drive/MyDrive/Python files/20210104-170423IrTimes.txt\"\n",
        "\n",
        "data_read_path = []\n",
        "dict_of_info = []\n",
        "\n",
        "data_read_path.append(\"/content/drive/MyDrive/Python files/20210201-202753IrTimes.txt\")\n",
        "dict_of_info.append({1:20493, 2 :20528, 4 :20516, 5 :20488})\n",
        "\n",
        "data_read_path.append( \"/content/drive/MyDrive/Python files/20210207-154302IrTimes.txt\")\n",
        "dict_of_info.append( {0: 20547, 1: 20493, 3: 62438, 4: 20516, 5: 20488})\n",
        "\n",
        "data_read_path.append( \"/content/drive/MyDrive/Python files/20210215-105316IrTimes.txt\")\n",
        "dict_of_info.append({0 :  20547 ,1 :  20493,3 :  62438 ,4 :  20516,5  : 20488})\n",
        "\n",
        "data_read_path.append(\"/content/drive/MyDrive/Python files/20210223-205817IrTimes.txt\")\n",
        "dict_of_info.append({3 : 62438 ,4 : 20516,1 : 20528,2 : 20493 ,5 : 20522  ,0:  20547})\n",
        "\n",
        "data_read_path.append(\"/content/drive/MyDrive/Python files/20210302-160001IrTimes.txt\")\n",
        "dict_of_info.append({0 :20632,1 :20616,2 :20513,3 :20488,4 :20529,5 :20595 })\n",
        "\n",
        "data_read_path.append( \"/content/drive/MyDrive/Python files/20210311-161231IrTimes.txt\")\n",
        "dict_of_info.append({0:20632, 1:20547, 2:20522, 3:20488, 4:20453, 5:20595})\n",
        "\n",
        "\n",
        "data_read_path.append( \"/content/drive/MyDrive/Python files/20210330-135215IrTimes.txt\")\n",
        "dict_of_info.append({0:20547, 1:20493, 3:62438, 4:20516 , 5:20488})\n",
        "\n",
        "\n",
        "dict_of_colony = {\n",
        "20595:\t(140,92),\n",
        "20632:\t(185,94),\n",
        "20522:\t(160,91),\n",
        "20516:\t(142,92),\n",
        "20493:\t(190,94),\n",
        "20616:\t(180,94),\n",
        "20513:\t(125,89),\n",
        "20488:\t(125,91),\n",
        "20528:\t(110,88),\n",
        "20547:\t(90,82),\n",
        "62438:\t(165,87),\n",
        "20592:\t(140,95),\n",
        "20529:\t(62,75),\n",
        "20453:\t(-1,-1) }\n",
        "\n",
        "dict_food = {\n",
        "20595:\t0,\n",
        "20632:\t0,\n",
        "20522:\t0,\n",
        "20516:\t0,\n",
        "20493:\t0,\n",
        "20616:\t0,\n",
        "20513:\t0,\n",
        "20488:\t0,\n",
        "20528:\t0,\n",
        "20547:\t0,\n",
        "62438:\t0,\n",
        "20592:\t0,\n",
        "20529:\t0,\n",
        "20453:\t0 }\n",
        "\n",
        "def nan_helper(y):\n",
        "    return np.isnan(y), lambda z: z.nonzero()[0]\n"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eiui7K7HyPb"
      },
      "source": [
        "def check_baskets(x,y):\n",
        "    if (math.sqrt((x - xlb)**2 + (y - ylb)**2) <= basketradius) or  (math.sqrt((x - xrb)**2 + (y - yrb)**2) <= basketradius):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdLqthFcSGmd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX5feDbtIeZs"
      },
      "source": [
        "def load_raw_file(mypath, session_index):\n",
        "  f = open(mypath, \"r\")\n",
        "  data = Lines = f.readlines()\n",
        "  list_locations = []\n",
        "  \n",
        "  for line in data:\n",
        "      columns = line.split(\",\")\n",
        "      #print(columns[13] + \" \" + columns[14])\n",
        "\n",
        "      xydata = columns[14].split(\" \")\n",
        "      xydata = [x for x in xydata if x]\n",
        "      xy_accuracy_data = columns[15].split(\" \")  # הוספתי\n",
        "      xy_accuracy_data = [x for x in xy_accuracy_data if x]  # הוספתי\n",
        "      if (len(xydata) != 2) or (len(xy_accuracy_data) != 2):  # הוספתי\n",
        "          continue\n",
        "\n",
        "      x_accuracy_data = (float(xy_accuracy_data[0].replace(\"[\", \"\").replace(\"]\", \"\")))  # הוספתי\n",
        "      y_accuracy_data = (float(xy_accuracy_data[1].replace(\"[\", \"\").replace(\"]\", \"\")))  # הוספתי\n",
        "      if (y_accuracy_data > accuracy_limit) or (x_accuracy_data > accuracy_limit):  # הוספתי\n",
        "          continue\n",
        "\n",
        "      x = (float(xydata[0].replace(\"[\", \"\").replace(\"]\", \"\")))\n",
        "      y = (float(xydata[1].replace(\"[\", \"\").replace(\"]\", \"\")))\n",
        "      dt = datetime.strptime(columns[0] + \" \" + columns[1] ,  \"%Y%m%d %H%M%S\").timestamp()  #20210104\n",
        "      t = np.array([int(columns[13]), dt, x, y])\n",
        "      list_locations += [t]\n",
        "\n",
        "      if check_baskets(x,y):\n",
        "        dict_food[dict_of_info[session_index][int(columns[13])]] += 1\n",
        "\n",
        "  list_array = np.array(list_locations)\n",
        "\n",
        "  f.close()\n",
        "\n",
        "  print(\"Done! func1!\")\n",
        "\n",
        "  return list_array\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2zy5_JqPOSE"
      },
      "source": [
        "def time_arrange_data(list_array):\n",
        "  t = 0\n",
        "  minimum_time = np.min(list_array[:,1])\n",
        "  maximum_time = np.max(list_array[:,1])\n",
        "  time_now = minimum_time\n",
        "  list_tag = np.unique(list_array[:,0])\n",
        "  main_data = np.zeros((len(list_tag),int((maximum_time-minimum_time)/per_unit), 2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  print(list_array[:,1])\n",
        "  print(minimum_time, maximum_time)\n",
        "  print(type(list_tag[0]))\n",
        "\n",
        "  tagids  = list_array[:,0]\n",
        "  dates = list_array[:,1]\n",
        "\n",
        "\n",
        "  while time_now <= (maximum_time - per_unit):\n",
        "    for a in range(len(list_tag)):\n",
        "      main_data[a,t,:] = np.mean(list_array[(tagids == list_tag[a]) & (dates> time_now) & (dates< (time_now + per_unit)) ,2:4],axis = 0)\n",
        "    t += 1  \n",
        "    time_now += per_unit\n",
        "\n",
        "  tag_nans = np.zeros((len(list_tag)))\n",
        "  for a in range(len(list_tag)):\n",
        "    tag_nans[a] = len(main_data[a,np.isnan(main_data[a,:,0]),0])/len(main_data[a,:,0]) > nans_tresh \n",
        "\n",
        "  main_data = main_data[~tag_nans.astype(bool)]\n",
        "  list_tag = list_tag[~tag_nans.astype(bool)]\n",
        "\n",
        "\n",
        "  print(\"Done! func2!\")\n",
        "  #אינטרפולציות\n",
        "  for a in range(len(list_tag)):\n",
        "    y = main_data[a,:,:]\n",
        "    nans, x= nan_helper(y)\n",
        "    y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
        "    main_data[a,:,:] = y\n",
        "  \n",
        "\n",
        "  return main_data, list_tag, minimum_time, maximum_time"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_1jRt0uidDc"
      },
      "source": [
        "\n",
        "def compute_distance_array(main_data, list_tag, minimum_time, maximum_time):\n",
        "  time_now = minimum_time\n",
        "  t = 0\n",
        "  distance_array = np.zeros((len(list_tag),int((maximum_time-minimum_time)/per_unit)))\n",
        "\n",
        "  while time_now <= (maximum_time - per_unit):\n",
        "    for a in range(len(list_tag)):\n",
        "      my_pos = main_data[a,t,:]\n",
        "      all_pos = main_data[:,t,:]\n",
        "      other_bats_pos = np.delete(all_pos,a, 0)\n",
        "      dist = []\n",
        "      for pos in other_bats_pos:\n",
        "        dist += [np.mean(np.linalg.norm(my_pos - pos))]\n",
        "      dist = np.array(dist)\n",
        "      dist = np.mean(dist)\n",
        "      distance_array[a,t] = dist\n",
        "    t += 1  \n",
        "    time_now += per_unit\n",
        "\n",
        "  \n",
        "  distance_array_in_zero = distance_array[0,:] < tresh_sleep_distance\n",
        "  for a in range(1, len(list_tag)):\n",
        "    distance_array_in_zero = (distance_array_in_zero &  (distance_array[a,:]<tresh_sleep_distance))\n",
        "  \n",
        "  return distance_array, distance_array_in_zero\n",
        "  \n",
        "  #plt.figure()\n",
        "  #plt.plot(distance_array_in_zero)\n",
        "  #plt.show()\n",
        "  #print(distance_array)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri7oIwZpg9g0"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG8gW63ekIXA"
      },
      "source": [
        "#מרחק שאני זזתי בקורולציה עם המרחק ששאר הקבוצה זזה\n",
        "def temp_function():\n",
        "  time_now = minimum_time + per_unit\n",
        "  t = 1\n",
        "  movment_array = np.zeros((len(list_tag),int((maximum_time-minimum_time)/per_unit)))\n",
        "\n",
        "  while time_now <= (maximum_time - per_unit):\n",
        "    for a in range(len(list_tag)):\n",
        "      my_pos = main_data[a,t,:]\n",
        "      my_prev_pos = main_data[a,t -1,:]\n",
        "      thedistance = np.linalg.norm(my_pos - my_prev_pos)\n",
        "      movment_array[a,t-1] = (thedistance )\n",
        "    t += 1  \n",
        "    time_now += per_unit\n",
        "\n",
        "  print(movment_array)\n",
        "  correlations = []\n",
        "  for a in range(len(list_tag)):\n",
        "    list_tag_temp = np.delete(np.array(range(len(list_tag))), a, 0).astype(int)\n",
        "    correlations.append(np.correlate(movment_array[a,:],np.mean(distance_array[list_tag_temp,:], axis=0)))\n",
        "    print(np.correlate(movment_array[a,:],np.mean(distance_array[list_tag_temp,:], axis=0)))"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y7JIAaRpigq"
      },
      "source": [
        "#המרחק שאני זזתי בקורלציה למרחק של שאר הקבוצה ממני\n",
        "def movment_array_creat(main_data, list_tag, minimum_time, maximum_time):\n",
        "  time_now = minimum_time + per_unit\n",
        "  t = 1\n",
        "  movment_array = np.zeros((len(list_tag),int((maximum_time-minimum_time)/per_unit)))\n",
        "\n",
        "  while time_now <= (maximum_time - per_unit):\n",
        "    for a in range(len(list_tag)):\n",
        "      my_pos = main_data[a,t,:]\n",
        "      my_prev_pos = main_data[a,t -1,:]\n",
        "      thedistance = np.linalg.norm(my_pos - my_prev_pos)\n",
        "      movment_array[a,t-1] = (thedistance )\n",
        "    t += 1  \n",
        "    time_now += per_unit\n",
        "\n",
        "  return movment_array\n",
        "  \n",
        "def correlations_generator(movment_array, distance_array, distance_array_in_zero):  \n",
        "  correlations = []\n",
        "  for a in range(len(list_tag)):\n",
        "    correlations.append(np.correlate(movment_array[a,~distance_array_in_zero],distance_array[a,~distance_array_in_zero]))\n",
        "\n",
        "  correlations = np.array(correlations)\n",
        "  print(correlations)\n",
        "  print(list_tag)\n",
        "  correlations = correlations-np.min(correlations)\n",
        "  correlations= correlations/np.max(correlations)\n",
        "  print(correlations)\n",
        "  return correlations#"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa-zxtblIjlk"
      },
      "source": [
        "def GMM_compute(main_data, list_tag, minimum_time, maximum_time):\n",
        "  maindatashape = np.shape(main_data)\n",
        "  f = np.reshape([main_data[:,:,:] ] , (maindatashape[0]*maindatashape[1] , 2) )\n",
        "  gm = GaussianMixture(n_components=gmmcomp, random_state=0).fit( f )\n",
        "  print(gm.means_)\n",
        "  print(gm.weights_)\n",
        "\n",
        " # fig , axs= plt.subplots(len(list_tag) ,figsize=(20,20), sharey=True)\n",
        "  for a in range(len(list_tag)):\n",
        "      gmpred = gm.predict(main_data[a,:,:])\n",
        "      \n",
        "     # axs[a].set_title(\"dominance is : \" + str(correlations[a]))\n",
        "      #axs[a].hist(gmpred , bins = range(gmmcomp+1))\n",
        "      #fig.savefig('result1.png')\n",
        "  return gm"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQp9kj7bO73L"
      },
      "source": [
        "def get_correlations_places(main_data, list_tag, minimum_time, maximum_time,gm):\n",
        "  all_cor_for_pos_list = []\n",
        "  for p in range(gmmcomp):\n",
        "    cor_for_pos_list = []\n",
        "    for a in range(len(list_tag)):\n",
        "        gmpred = (gm.predict(main_data[a,:,:])   ).astype(int)\n",
        "        #plt.plot(gmpred )\n",
        "        cor_for_pos_list.append((correlations[a] , len(gmpred[gmpred==p])))\n",
        "    cor_for_pos_list = np.array(cor_for_pos_list)\n",
        "    gmmcount = cor_for_pos_list[:,1]\n",
        "    gmmcount = gmmcount - np.min(gmmcount)\n",
        "    gmmcount = gmmcount/np.max(gmmcount)\n",
        "    cor_for_pos_list[:,1] = gmmcount\n",
        "    all_cor_for_pos_list.append(cor_for_pos_list)\n",
        "  return np.array(all_cor_for_pos_list) \n",
        "  #fig.savefig('dominanceVsHome0.png')"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txuy4SGzMiNA",
        "outputId": "4774b904-e28f-453f-ea2f-456588440c7a"
      },
      "source": [
        "all_path_data =[]\n",
        "session_index = 0\n",
        "for p in data_read_path:\n",
        "  main_data, list_tag, minimum_time, maximum_time = time_arrange_data(load_raw_file(p, session_index))\n",
        "  distance_array, distance_array_in_zero = compute_distance_array(main_data, list_tag, minimum_time, maximum_time)\n",
        "  movment_array = movment_array_creat(main_data, list_tag, minimum_time, maximum_time)\n",
        "  correlations = correlations_generator(movment_array, distance_array, distance_array_in_zero)\n",
        "  gm = GMM_compute(main_data, list_tag, minimum_time, maximum_time)\n",
        "  all_cor_for_pos_list = get_correlations_places(main_data, list_tag, minimum_time, maximum_time,gm)\n",
        "  all_path_data.append((all_cor_for_pos_list, gm.means_, list_tag, correlations, main_data, minimum_time, maximum_time))\n",
        "  session_index += 1\n",
        "  print(list_tag)\n",
        "  print(\"Done! Part1!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done! func1!\n",
            "[1.61221128e+09 1.61221128e+09 1.61221128e+09 ... 1.61231476e+09\n",
            " 1.61231476e+09 1.61231476e+09]\n",
            "1612211276.0 1612314761.0\n",
            "<class 'numpy.float64'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done! func2!\n",
            "[[ 4475059.83204483]\n",
            " [11007617.68162075]\n",
            " [15433689.09054378]\n",
            " [ 8438087.51103766]]\n",
            "[1. 2. 4. 5.]\n",
            "[[0.        ]\n",
            " [0.59611085]\n",
            " [1.        ]\n",
            " [0.36163535]]\n",
            "[[197.01920518  59.47682463]\n",
            " [411.42731197 272.05013797]\n",
            " [492.8915244  133.89295089]]\n",
            "[0.12419863 0.31841503 0.55738634]\n",
            "[1. 2. 4. 5.]\n",
            "Done! Part1!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done! func1!\n",
            "[1.61271258e+09 1.61271259e+09 1.61271260e+09 ... 1.61301981e+09\n",
            " 1.61301981e+09 1.61301981e+09]\n",
            "1612712585.0 1613019814.0\n",
            "<class 'numpy.float64'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOwdEtnXyrXu"
      },
      "source": [
        "save_path = \"/content/drive/MyDrive/Python files/ALL_DATA.p\"\n",
        "pickle.dump( all_path_data, open( save_path, \"wb\" ) ) #save\n",
        "\n",
        "save_path_dict_food = \"/content/drive/MyDrive/Python files/DICT_FOOD.p\"\n",
        "pickle.dump( dict_food, open( save_path_dict_food, \"wb\" ) ) #save\n",
        "\n",
        "dict_food = pickle.load( open( save_path_dict_food, \"rb\" ) ) #load\n",
        "all_path_data = pickle.load( open( save_path, \"rb\" ) ) #load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRohfVOiW7cR"
      },
      "source": [
        "posind =0\n",
        "for p in range(len(data_read_path)):\n",
        "  plt.scatter(all_path_data[p][0][posind][:,0],all_path_data[p][0][posind][:,1])\n",
        "    #plt.scatter(all_path_data[p][0][0,:,:])\n",
        " # print(all_path_data[p][0][posind])\n",
        "#model = LinearRegression().fit(x, y)\n",
        "plt.figure()\n",
        "posind =1\n",
        "for p in range(len(data_read_path)):\n",
        "  plt.scatter(all_path_data[p][0][posind][:,0],all_path_data[p][0][posind][:,1])\n",
        "plt.figure()\n",
        "posind =2\n",
        "for p in range(len(data_read_path)):\n",
        "  plt.scatter(all_path_data[p][0][posind][:,0],all_path_data[p][0][posind][:,1])\n",
        "\n",
        "#print(all_path_data[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBlslm0mPA99"
      },
      "source": [
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#fig= plt.figure()\n",
        "\n",
        "#f = np.array(range(gmmcomp))\n",
        "#for i, txt in enumerate(f):\n",
        "   # plt.annotate(txt, (gm.means_[i,0], gm.means_[i,1]))\n",
        "    \n",
        "#plt.scatter(gm.means_[:, 0], gm.means_[:, 1])\n",
        "#plt.show()\n",
        "#fig.savefig('mapofplaces.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJmdMWg-9gvA"
      },
      "source": [
        "  fig = plt.figure()\n",
        "\n",
        "  for a in range(len(list_tag)):\n",
        "      gmpred = (gm.predict(main_data[a,:,:])   ).astype(int)\n",
        "      #plt.plot(gmpred )\n",
        "      plt.scatter(correlations[a] , len(gmpred[gmpred==0]))\n",
        "      \n",
        "  fig.savefig('dominanceVsHome0.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0o50k-5oAv4p"
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "for a in range(len(list_tag)):\n",
        "    gmpred = (gm.predict(main_data[a,:,:])   ).astype(int)\n",
        "    #plt.plot(gmpred )\n",
        "    plt.scatter(correlations[a] , len(gmpred[gmpred==1]))\n",
        "    \n",
        "fig.savefig('dominanceVsHome1.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz1koj-eklvo"
      },
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "for a in range(len(list_tag)):\n",
        "    gmpred = (gm.predict(main_data[a,:,:])   ).astype(int)\n",
        "    #plt.plot(gmpred )\n",
        "    plt.scatter(correlations[a] , len(gmpred[gmpred==2]))\n",
        "    \n",
        "fig.savefig('dominanceVsHome2.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SoBkb16vTMe"
      },
      "source": [
        "#dict_of_colony = {RFID: (w,AL)}\n",
        "#dict_of_info = \n",
        "#all_path_data.append((all_cor_for_pos_list, gm.means_, list_tag, correlations))\n",
        "\n",
        "#צריך לנרמל לפי מספר הפעמים שעטלף השתתף בניסוי\n",
        "\n",
        "\n",
        "corelation_arm_list = []\n",
        "\n",
        "for a in range(len(all_path_data)):\n",
        "  list_tag_tempy = all_path_data[a][2]\n",
        "  for b in range(len(list_tag_tempy)):\n",
        "    cor_temp =np.where(np.sort(all_path_data[a][3]) == all_path_data[a][3][b])[0] / len(list_tag_tempy)\n",
        " \n",
        "    tmpallweight = []\n",
        "    for t1 in range(len(list_tag_tempy)):\n",
        "        tmpallweight.append( dict_of_colony[  dict_of_info[a][   list_tag_tempy[t1]   ]    ][1])\n",
        "    \n",
        "    all_weight =np.sort(np.array(tmpallweight))\n",
        "    my_weight =  dict_of_colony[  dict_of_info[a][   list_tag_tempy[b]   ]    ][1]\n",
        "    if(my_weight< 80 or my_weight == -1):\n",
        "      continue\n",
        "  #  print(all_weight)\n",
        "    weight_temp = np.mean(np.where(all_weight ==my_weight)) / len(list_tag_tempy)\n",
        "    if(weight_temp > 0.7):\n",
        "       print( dict_of_info[a][   list_tag_tempy[b]   ])\n",
        "   # print(weight_temp)\n",
        "    corelation_arm_list.append((cor_temp, weight_temp))\n",
        "    #corelation_arm_list.append((cor_temp[0], dict_of_colony[  dict_of_info[a][   list_tag_tempy[b]   ]    ][0]))\n",
        "corelation_arm_list = np.array(corelation_arm_list)\n",
        "\n",
        "#plt.figure()\n",
        "for i in range (5):\n",
        "\n",
        "  plt.scatter(i*0.2, np.mean(corelation_arm_list[(corelation_arm_list[:,0] > (i*0.2))&(corelation_arm_list[:,0] <= ((i+1)*0.2)),1]))\n",
        "plt.savefig('dominanceVsWeight.png')\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(corelation_arm_list[:,0], corelation_arm_list[:,1])\n",
        "#print(np.corrcoef(corelation_arm_list[:,0], corelation_arm_list[:,1]))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1fniWd42ecA"
      },
      "source": [
        "\n",
        "rfid_list = {}\n",
        "\n",
        "for a in range(len(all_path_data)):\n",
        "  list_tag_tempy = all_path_data[a][2]\n",
        "  for b in range(len(list_tag_tempy)):\n",
        "      my_rfid = (dict_of_info[a][int(all_path_data[a][2][b])])\n",
        "    #  print(my_rfid)\n",
        "      if my_rfid not in rfid_list.keys():\n",
        "        rfid_list[my_rfid] = np.zeros(len(all_path_data))\n",
        "      \n",
        "      rfid_list[my_rfid][a] = all_path_data[a][3][b] +1\n",
        "\n",
        "temp_list =[]\n",
        "index_of_rfids = []\n",
        "\n",
        "for rfid in rfid_list:\n",
        "  temp_list.append(rfid_list[rfid])\n",
        "  index_of_rfids.append(rfid)\n",
        "\n",
        "session_bats_dominnace_array  = np.array(temp_list)\n",
        "\n",
        "plt.pcolormesh(session_bats_dominnace_array)\n",
        "plt.colorbar()\n",
        "\n",
        "print(index_of_rfids)\n",
        "plt.savefig('DomiMap.png')\n",
        "#fig.savefig('DomiMap.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SPUySOz19rN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}